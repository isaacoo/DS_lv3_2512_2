{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765c0422",
   "metadata": {},
   "source": [
    "# 문제 6\n",
    "\n",
    "[Kaggle 형] train_prob.csv로 failure 예측하는 모델을 만들고, \n",
    "\n",
    "test_prob.csv에 대한 failure가 1일 확률 예측하여 다음과 같은 형식의 answer6.csv를 만들어라. \n",
    "\n",
    "측정 지표는 AUC(area under of ROC curve)이다. id 는 테스트 케이스의 id 이고, failure에는 failure가 1이 될 확률이다.\n",
    "\n",
    "id,failure\n",
    "\n",
    "16115, 0.1\n",
    "\n",
    "16116, 0.2\n",
    "\n",
    "\n",
    "**강사: 멀티캠퍼스 강선구(sunku0316.kang@multicampus.com, sun9sun9@gmail.com)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ff1fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (default, Oct 17 2019, 06:10:02) \n",
      "[GCC 8.3.0]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n",
      "xgboost 0.80\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels, xgb]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac71869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_prob.csv', index_col = 'id')\n",
    "df_test = pd.read_csv('test_prob.csv', index_col = 'id')\n",
    "s_kaggle_ans = pd.read_csv('test_prob_ans.csv', index_col = 'id')['failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f35e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.assign(\n",
    "    na_1 = lambda x: x['measurement_3'].isna(),\n",
    "    na_2 = lambda x: x['measurement_5'].isna()\n",
    ")\n",
    "df_test = df_test.assign(\n",
    "    na_1 = lambda x: x['measurement_3'].isna(),\n",
    "    na_2 = lambda x: x['measurement_5'].isna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c548bff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(C    5765\n",
       " E    5343\n",
       " B    5250\n",
       " A    5100\n",
       " Name: product_code, dtype: int64,\n",
       " D    5112\n",
       " Name: product_code, dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_train['product_code'].value_counts(),\n",
    "    df_test['product_code'].value_counts(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8174fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "imp = IterativeImputer(\n",
    "    estimator = LinearRegression(fit_intercept = True),\n",
    "    random_state=123\n",
    ")\n",
    "df_train[X_imp] = df_train.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(imp.fit_transform(x), index = x.index, columns = X_imp)\n",
    ")\n",
    "df_test[X_imp] = df_test.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(imp.fit_transform(x), index = x.index, columns = X_imp)\n",
    ")\n",
    "X_mean  = ['measurement_{}'.format(i) for i in range(10, 17)]\n",
    "df_train[X_mean] = df_train.groupby('product_code')[X_mean].transform(lambda x: x.fillna(x.mean()))\n",
    "df_test[X_mean] = df_test.groupby('product_code')[X_mean].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfd1187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.concat([df_train['loading'], df_test['loading']]).mean()\n",
    "df_train['loading'] = df_train['loading'].fillna(m)\n",
    "df_test['loading'] = df_test['loading'].fillna(m)\n",
    "df_train['loading_log'] = np.log(df_train['loading'])\n",
    "df_test['loading_log'] = np.log(df_test['loading'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850e1e2",
   "metadata": {},
   "source": [
    "- 문제 1.\n",
    "\n",
    "na_1 = measurement_3의 결측여부\n",
    "\n",
    "na_2 = measurement_3의 결측여부\n",
    "\n",
    "failure 연관성이 있다.\n",
    "\n",
    "- 문제 2.\n",
    "\n",
    "loading_log = np.log(log)\n",
    "\n",
    "attribute_0와 attribute_1은 failure와 상관없음\n",
    "\n",
    "loading과 product_code는 상관없음\n",
    "\n",
    "- 문제 3.\n",
    "\n",
    "loading의 결측치: loading의 평균으로 처리 \n",
    "\n",
    "std: loading, measurement_0~17  pt: na_1, na_2 + LR = AUC: 0.5792951262053387\n",
    "\n",
    "SFS: ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17', 'na_1'] + LR = AUC: 0.5838326230092876\n",
    "        \n",
    "- 문제 4.\n",
    "\n",
    "LDA: Transformer ['measurement_0~17']\n",
    "     Predictor ?\n",
    "        \n",
    "PCA n_components = 7 : std ['measurement_0~17'] + LR : 0.581757510516433\n",
    "        \n",
    "- 문제 5\n",
    "\n",
    "GridSearch + RandomForest: {'n_estimators': 15, 'max_depth': 7, 'min_samples_split': 512},: 0.5687712018291998"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7dad7f",
   "metadata": {},
   "source": [
    "# Kaggle형 풀이 단계\n",
    "\n",
    "Step 0: Kaggle용 데이터셋을 만든다.\n",
    "\n",
    "Step 1: 검증 방법을 정하고, 검증 루틴을 만듭니다.\n",
    "\n",
    "Step 2: Baseline 모델을 만듭니다\n",
    "\n",
    "Step 3: 모델 선택 루틴을 만듭니다.\n",
    "\n",
    "|id|failure|\n",
    "|----|----|\n",
    "|16115| 0.1|\n",
    "|16116| 0.2|\n",
    "\n",
    "....\t\n",
    "\n",
    "Step 4: 모델 개선 작업을 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f4075",
   "metadata": {},
   "source": [
    "## Step1: 검증 방법을 정하고, 검증 루틴을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "072a7559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['product_code', 'loading', 'attribute_0', 'attribute_1',\n",
       "       'attribute_2', 'attribute_3', 'measurement_0', 'measurement_1',\n",
       "       'measurement_2', 'measurement_3', 'measurement_4', 'measurement_5',\n",
       "       'measurement_6', 'measurement_7', 'measurement_8', 'measurement_9',\n",
       "       'measurement_10', 'measurement_11', 'measurement_12',\n",
       "       'measurement_13', 'measurement_14', 'measurement_15',\n",
       "       'measurement_16', 'measurement_17', 'na_1', 'na_2', 'loading_log'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = df_test.columns.tolist()\n",
    "np.array(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f30468a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A', 'B', 'C', 'E'], dtype=object), array(['D'], dtype=object))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_code'].unique(), df_test['product_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c77bdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'E'] ['C']\n",
      "['A' 'B' 'C'] ['E']\n",
      "['A' 'C' 'E'] ['B']\n",
      "['B' 'C' 'E'] ['A']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "gkf = GroupKFold(4)\n",
    "for train_idx, valid_idx in gkf.split(df_train[X_all], df_train['failure'], groups = df_train['product_code']):\n",
    "    print(\n",
    "        df_train.iloc[train_idx]['product_code'].unique(), \n",
    "        df_train.iloc[valid_idx]['product_code'].unique()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ceaa21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "gkf = GroupKFold(4)\n",
    "hist = list()\n",
    "def eval_model(model_name, clf):\n",
    "    \"\"\"\n",
    "        모델의 인스턴스를 받아 검증 결과(AUC) 를 구합니다.\n",
    "        1. GroupKFold 분리 검증 - df_train, groups = product_code\n",
    "        2. df_train 대한 교차검증결과에 대한 AUC를 구합니다.\n",
    "        3. 주어진 모델명으로 평가 결과를 저장합니다. Format: Valid: {:.5f}±{:.5f}, Train: {:.5f}±{:.5f}\n",
    "        4. 가장 최근의 수행결과를 보여 주어 선택하는데 활용하도록 합니다.\n",
    "    Parameters:\n",
    "        model_name: str, 모델의 이름,\n",
    "        clf: sklearn object, 모델 인스턴스\n",
    "    \"\"\"\n",
    "    result = cross_validate(\n",
    "        clf, df_train[X_all], df_train['failure'], groups = df_train['product_code'], scoring = 'roc_auc', cv = gkf, \n",
    "        return_train_score = True\n",
    "    )\n",
    "    result_str = \"Valid: {:.5f}±{:.5f}, Train: {:.5f}±{:.5f}\".format(\n",
    "        result['test_score'].mean(), result['test_score'].std(),\n",
    "        result['train_score'].mean(), result['train_score'].std()\n",
    "    )\n",
    "    hist.append(\n",
    "        pd.Series(['model_name', result_str], index = ['name', 'result'])\n",
    "    )\n",
    "    display(\n",
    "        pd.DataFrame(hist).groupby('name').last()\n",
    "    )\n",
    "    return result_str\n",
    "\n",
    "# 모델 선택 루틴입니다. (Step 3)\n",
    "def select_model(clf):\n",
    "    \"\"\"\n",
    "        1. 전체 학습데이터(df_train)로 학습을 합니다. \n",
    "        2. df_test에 대한 예측을 합니다.\n",
    "        3. 예측 결과를 출력양식(id, failure)에 맞춰 csv파일을 만듭니다.\n",
    "        4. 자가 채점을 위한 예측 결과를 반환합니다.\n",
    "    Parameters: \n",
    "        clf: sklearn object, 모델 인스턴스\n",
    "    Returns: 1차원 np.ndarray\n",
    "        예측 결과\n",
    "    \"\"\"\n",
    "    clf.fit(df_train[X_all], df_train['failure'])\n",
    "    prd = clf.predict_proba(df_test[X_all])[:, 1]\n",
    "    pd.DataFrame({\n",
    "        'id': df_test.index,\n",
    "        'failure': prd\n",
    "    }).to_csv('answer6.csv', index = None)\n",
    "    return prd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1631e458",
   "metadata": {},
   "source": [
    "## Step2: Baseline 모델을 만듭니다.\n",
    "\n",
    "std: \\['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17'\\] pt: \\[ 'na_1'\\] -> LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d00ff3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>model_name</td>\n",
       "      <td>Valid: 0.58937±0.00380, Train: 0.59190±0.00146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    result\n",
       "name                                                      \n",
       "model_name  Valid: 0.58937±0.00380, Train: 0.59190±0.00146"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Valid: 0.58937±0.00380, Train: 0.59190±0.00146'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17']),\n",
    "    ('pt', 'passthrough', ['na_1'])\n",
    "])\n",
    "\n",
    "clf_lr = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "eval_model('baseline', clf_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9b576",
   "metadata": {},
   "source": [
    "## Step3: 모델 선택 루틴을 만듭니다.\n",
    "\n",
    "id,failure\n",
    "\n",
    "16115, 0.1\n",
    "\n",
    "16116, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e83ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자가채점: 0.5883911870503598\n"
     ]
    }
   ],
   "source": [
    "prd = select_model(clf_lr)\n",
    "print(\"자가채점:\", roc_auc_score(s_kaggle_ans, prd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fba5505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([16115, 16116, 16117, 16118, 16119, 16120, 16121, 16122, 16123,\n",
       "            16124,\n",
       "            ...\n",
       "            21217, 21218, 21219, 21220, 21221, 21222, 21223, 21224, 21225,\n",
       "            21226],\n",
       "           dtype='int64', name='id', length=5112)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
